#!/bin/bash -e

CHARM="cinder"

COMMON_PACKAGES="cinder-common python-mysqldb gdisk haproxy"
API_PACKAGES="cinder-api"
VOL_PACKAGES="cinder-volume"
SCHED_PACKAGES="cinder-scheduler"

CINDER_CONF="/etc/cinder/cinder.conf"
API_CONF="/etc/cinder/api-paste.ini"

CONFIG_CHANGED="False"

HOOKS_DIR="$CHARM_DIR/hooks"

if [[ -e $HOOKS_DIR/lib/openstack-common ]] ; then
  . $HOOKS_DIR/lib/openstack-common
else
  juju-log "Couldn't load $HOOKS_DIR/openstack-common" && exit 1
fi

service_enabled() {
  # return 0 if a specific cinder service is enabled in config
  # "enabled-services"
  local enabled_services=$(config-get enabled-services)
  [[ "$enabled_services" == "all" ]] && return 0
  local svc="$1"
  local enabled=$(echo $enabled_services | sed -e 's/,/ /g')
  for s in $enabled ; do
   [[ "$svc" == "$s" ]] && return 0
  done
  return 1
}

determine_packages() {
  # determine packages to be installed based on what services are enabled.
  local pkgs="$COMMON_PACKAGES"
  local enabled_services=$(config-get enabled-services)

  if [[ "$enabled_services" == "all" ]] ; then
    pkgs="$pkgs $API_PACKAGES $VOL_PACKAGES $SCHED_PACKAGES"
  else
    service_enabled "api" && pkgs="$pkgs $API_PACKAGES"
    service_enabled "scheduler" && pkgs="$pkgs $SCHED_PACKAGES"
    service_enabled "volume" && pkgs="$pkgs $VOL_PACKAGES"
  fi
  echo "$pkgs"
}

function set_or_update {
  # Set a config option in nova.conf or api-paste.ini, depending
  # Defaults to updating nova.conf
  local KEY="$1"
  local VALUE="$2"
  local CONF_FILE="$3"
  local pattern=""
  [[ -z $KEY ]] && error_out "set_or_update: value $VALUE missing KEY"
  [[ -z $VALUE ]] && error_out "set_or_update: key $KEY missing VALUE"
  [[ -z "$CONF_FILE" ]] && CONF_FILE=$CINDER_CONF

  case "$CONF_FILE" in
    "$CINDER_CONF") match="^$KEY = "
                    pattern="$match"
                    out="$KEY = "
                    ;;
    "$API_CONF") match="^$KEY = "
                 pattern="$match"
                 out="$KEY = "
                 ;;
    *) juju-log "ERROR: set_or_update: Invalid CONF_FILE ($CONF_FILE)"
  esac

  grep -q "$match$VALUE" $CONF_FILE &&
    juju-log "cinder: $KEY=$VALUE already in set in $CONF_FILE" && return 0

  if grep -q "$match" $CONF_FILE ; then
    juju-log "cinder: Updating $CONF_FILE, $KEY=$VALUE"
    sed -i "s|\($pattern\).*|\1$VALUE|" $CONF_FILE
  else
    juju-log "cinder: Setting new option $KEY=$VALUE in $CONF_FILE"
    echo "$out$VALUE" >>$CONF_FILE
  fi
  CONFIG_CHANGED="True"
}

cinder_ctl() {
  local svc="$1"
  local action="$2"
  local svcs=""
  if [[ "$svc" == "all" ]] ; then
    service_enabled "api" && svcs="$svcs cinder-api"
    service_enabled "scheduler" && svcs="$svcs cinder-scheduler"
    service_enabled "volume" && svcs="$svcs cinder-volume"
  else
    svcs=$svc
  fi
  SERVICES=$svcs
  service_ctl all $action
}

clean_storage() {
  # if configured to overwrite existing storage, we unmount the block-dev
  # if mounted and clear any previous pv signatures
  local block_dev="$1"
  juju-log "Preparing storage '$block_dev'"
  if grep -q "^$block_dev" /proc/mounts ; then
    mp=$(grep "^$block_dev" /proc/mounts   | awk '{ print $2 }')
    juju-log "Unmounting $block_dev from $mp"
    umount "$mp" || error_out "ERROR: Could not unmount storage from $mp"
  fi
  if pvdisplay "$block_dev" >/dev/null 2>&1 ; then
    juju-log "Removing existing LVM PV signatures from $block_dev"

    # deactivate any volgroups that may be built on this dev
    vg=$(pvdisplay $block_dev | grep "VG Name" | awk '{ print $3 }')
    if [[ -n "$vg" ]] ; then
      juju-log "Deactivating existing volume group: $vg"
      vgchange -an "$vg" ||
        error_out "ERROR: Could not deactivate volgroup $vg.  Is it in use?"
    fi
    echo "yes" | pvremove -ff "$block_dev" ||
      error_out "Could not pvremove $block_dev"
  else
    juju-log "Zapping disk of all GPT and MBR structures"
    sgdisk --zap-all $block_dev ||
      error_out "Unable to zap $block_dev"
  fi
}

function get_block_device() {
  # given a string, return full path to the block device for that
  # if input is not a block device, find a loopback device
  local input="$1"

  case "$input" in
    /dev/*) echo "$input"; return 0;;
    /*) :;;
    *) echo "/dev/$input"; return 0;;
  esac

  # this represents a file
  # support "/path/to/file|5G"
  local fpath size oifs="$IFS"
  if [ "${input#*|}" != "${input}" ]; then
    size=${input##*|}
    fpath=${input%|*}
  else
    fpath=${input}
    size=5G
  fi

  ## loop devices are not namespaced.  This is bad for containers.
  ## it means that the output of 'losetup' may have the given $fpath
  ## in it, but that may not represent this containers $fpath, but
  ## another containers.  To address that, we really need to
  ## allow some uniq container-id to be expanded within path.
  ## TODO: find a unique container-id that will be consistent for
  ##       this container throughout its lifetime and expand it
  ##       in the fpath.
  # fpath=${fpath//%{id}/$THAT_ID}

  local found=""
  # parse through 'losetup -a' output, looking for this file
  # output is expected to look like:
  #   /dev/loop0: [0807]:961814 (/tmp/my.img)
  found=$(losetup -a |
    awk 'BEGIN { found=0; }
         $3 == f { sub(/:$/,"",$1); print $1; found=found+1; }
         END { if( found == 0 || found == 1 ) { exit(0); }; exit(1); }' \
         f="($fpath)")

  if [ $? -ne 0 ]; then
    echo "multiple devices found for $fpath: $found" 1>&2
    return 1;
  fi

  [ -n "$found" -a -b "$found" ] && { echo "$found"; return 1; }

  if [ -n "$found" ]; then
    echo "confused, $found is not a block device for $fpath";
    return 1;
  fi

  # no existing device was found, create one
  mkdir -p "${fpath%/*}"
  truncate --size "$size" "$fpath" ||
    { echo "failed to create $fpath of size $size"; return 1; }

  found=$(losetup --find --show "$fpath") ||
    { echo "failed to setup loop device for $fpath" 1>&2; return 1; }

  echo "$found"
  return 0
}

prepare_storage() {
  # prepare a local block device for use by cinder. this involves potentially
  # cleaning/unmounting existing storage, init'ing the device as a LVM PV,
  # and creating a VG.
  local block_dev="$1"
  local vol_group="$2"
  local overwrite="$3"

  [[ -z "$block_dev" ]] || [[ -z "$vol_group" ]] &&
    error_out "cinder: prepare_storage() missing input: block_dev|vol_group"

  local device=""
  device=$(get_block_device "$block_dev") ||
    error_out "failed to get device for $block_dev"

  juju-log "using $device for block-device input of $block_dev"

  [ -b "$device" ] ||
    error_out "$device is not a valid block device";

  [ "$overwrite" != "True" -a "$overwrite" != "true" ] ||
    clean_storage "$device"

  juju-log "Initializing $device as a PV..."
  pvcreate "$device" || error_out "Could not initialize PV: $device"

  juju-log "Creating volume group $vol_group on $device"
  vgcreate "$vol_group" "$device" ||
    error_out "Could not create volume group: $vol_group"
  return 0
}

configure_https() {
  # request openstack-common setup reverse proxy mapping for API and registry
  # servers
  service_enabled "api" || return 0
  local cfg_api_port=$(config-get api-listening-port)
  service_ctl cinder-api stop
  if [[ -n "$(peer_units)" ]] || is_clustered ; then
    # haproxy may already be configured. need to push it back in the request
    # pipeline in preparation for a change from:
    #  from:  haproxy (8776) -> cinder-api (8766)
    #  to:    ssl (8776) -> haproxy (8766) -> cinder-api (8756)
    local next_server=$(determine_haproxy_port $cfg_api_port)
    local api_port=$(determine_api_port $cfg_api_port)
    configure_haproxy "cinder_api:$next_server:$api_port"
  else
    # if not clustered, the cinder-api is next in the pipeline.
    local api_port=$(determine_api_port $cfg_api_port)
    local next_server=$api_port
  fi

  # setup https to point to either haproxy or directly to api server, depending.
  setup_https $cfg_api_port:$next_server

  # configure servers to listen on new ports accordingly.
  set_or_update osapi_volume_listen_port "$api_port"
  service_ctl cinder-api start

  local r_id=""
  # (re)configure ks endpoint accordingly in ks and nova.
  for r_id in $(relation-ids identity-service) ; do
    keystone_joined "$r_id"
  done
}

do_openstack_upgrade() {
  local rel="$1"
  shift
  local packages=$@
  configure_install_source "$rel"
  apt-get update
  DEBIAN_FRONTEND=noninteractive apt-get \
     --option Dpkg::Options::=--force-confnew -y \
     install --no-install-recommends $packages
  # update new configs for all possible relations
  # mysql
  for r_id in $(relation-ids shared-db); do
    for unit in $(relation-list -r $r_id) ; do
      juju-log "$CHARM: Configuring database after upgrade."
      db_changed $r_id $unit
    done
  done
  # rabbitmq-server
  for r_id in $(relation-ids amqp); do
    for unit in $(relation-list -r $r_id) ; do
      juju-log "$CHARM: Configuring amqp after upgrade."
      amqp_changed $r_id $unit
    done
  done
  # keystone
  for r_id in $(relation-ids identity-service); do
    for unit in $(relation-list -r $r_id) ; do
      juju-log "$CHARM: Configuring identity service after upgrade."
      keystone_changed $r_id $unit
    done
  done
  # ceph
  for r_id in $(relation-ids ceph); do
    # ensure librbd gets updated with openstack
    apt-get -y install librbd1
    for unit in $(relation-list -r $r_id) ; do
      juju-log "$CHARM: Configuring ceph client after upgarde."
      ceph_changed $r_id $unit
    done
  done
}
